{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86d549ac-f8f4-4db0-bdbf-10f6e25864a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer\n",
    "from model.model_minimind import MiniMindConfig, MiniMindForCausalLM\n",
    "from model.model_lora import *\n",
    "from trainer.trainer_utils import setup_seed\n",
    "import pandas as pd\n",
    "import json\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06858781-c832-4ef6-acd5-480afe78faeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LOC = '/root/xlcoder/MiniMind2-Small/dataset'\n",
    "INSTR_LOC = '/root/xlcoder/MiniMind2-Small/hands-on'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9240483e-01f7-426d-834b-a4b130be8507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(args):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.load_from)\n",
    "    if 'model' in args.load_from:\n",
    "        model = MiniMindForCausalLM(MiniMindConfig(\n",
    "            hidden_size=args.hidden_size,\n",
    "            num_hidden_layers=args.num_hidden_layers,\n",
    "            use_moe=bool(args.use_moe),\n",
    "            inference_rope_scaling=args.inference_rope_scaling\n",
    "        ))\n",
    "        moe_suffix = '_moe' if args.use_moe else ''\n",
    "        ckp = f'./{args.save_dir}/{args.weight}_{args.hidden_size}{moe_suffix}.pth'\n",
    "        model.load_state_dict(torch.load(ckp, map_location=args.device), strict=True)\n",
    "        if args.lora_weight != 'None':\n",
    "            apply_lora(model)\n",
    "            load_lora(model, f'./{args.save_dir}/lora/{args.lora_weight}_{args.hidden_size}.pth')\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(args.load_from, trust_remote_code=True)\n",
    "    print(f'MiniMindæ¨¡å‹å‚æ•°: {sum(p.numel() for p in model.parameters()) / 1e6:.2f} M(illion)')\n",
    "    return model.eval().to(args.device), tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3595d7b9-622d-4e30-9c38-18207fca5ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\n",
    "    # 'load_from':'/root/xlcoder/MiniMind2-Small/MiniMind2',\n",
    "    'load_from': '../model',\n",
    "    'save_dir': '../out',\n",
    "    # 'weight': 'full_sft',\n",
    "    'weight': 'pretrain',\n",
    "    'lora_weight': 'None',\n",
    "    # 'hidden_size': 768,\n",
    "    'hidden_size': 512,\n",
    "    # 'num_hidden_layers': 16,\n",
    "    'num_hidden_layers': 8,\n",
    "    'use_moe': 0,\n",
    "    'inference_rope_scaling': False,\n",
    "    'max_new_tokens':8192,\n",
    "    'temperature':0.85,\n",
    "    'top_p':0.85,\n",
    "    'historys':0,\n",
    "    'device':'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'times': 1,\n",
    "    'count_only': False\n",
    "}\n",
    "args = json.loads(json.dumps(args), object_hook=lambda d: SimpleNamespace(**d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80b48ad5-390f-4064-bdde-8a1678094188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>filename</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>001.txt</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>002.txt</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>003.txt</td>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>004.txt</td>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>005.txt</td>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Dome...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2220</th>\n",
       "      <td>tech</td>\n",
       "      <td>397.txt</td>\n",
       "      <td>BT program to beat dialler scams</td>\n",
       "      <td>BT is introducing two initiatives to help bea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2221</th>\n",
       "      <td>tech</td>\n",
       "      <td>398.txt</td>\n",
       "      <td>Spam e-mails tempt net shoppers</td>\n",
       "      <td>Computer users across the world continue to i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2222</th>\n",
       "      <td>tech</td>\n",
       "      <td>399.txt</td>\n",
       "      <td>Be careful how you code</td>\n",
       "      <td>A new European directive could put software w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2223</th>\n",
       "      <td>tech</td>\n",
       "      <td>400.txt</td>\n",
       "      <td>US cyber security chief resigns</td>\n",
       "      <td>The man making sure US computer networks are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>tech</td>\n",
       "      <td>401.txt</td>\n",
       "      <td>Losing yourself in online gaming</td>\n",
       "      <td>Online role playing games are time-consuming,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2225 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category filename                              title  \\\n",
       "0     business  001.txt  Ad sales boost Time Warner profit   \n",
       "1     business  002.txt   Dollar gains on Greenspan speech   \n",
       "2     business  003.txt  Yukos unit buyer faces loan claim   \n",
       "3     business  004.txt  High fuel prices hit BA's profits   \n",
       "4     business  005.txt  Pernod takeover talk lifts Domecq   \n",
       "...        ...      ...                                ...   \n",
       "2220      tech  397.txt   BT program to beat dialler scams   \n",
       "2221      tech  398.txt    Spam e-mails tempt net shoppers   \n",
       "2222      tech  399.txt            Be careful how you code   \n",
       "2223      tech  400.txt    US cyber security chief resigns   \n",
       "2224      tech  401.txt   Losing yourself in online gaming   \n",
       "\n",
       "                                                content  \n",
       "0      Quarterly profits at US media giant TimeWarne...  \n",
       "1      The dollar has hit its highest level against ...  \n",
       "2      The owners of embattled Russian oil giant Yuk...  \n",
       "3      British Airways has blamed high fuel prices f...  \n",
       "4      Shares in UK drinks and food firm Allied Dome...  \n",
       "...                                                 ...  \n",
       "2220   BT is introducing two initiatives to help bea...  \n",
       "2221   Computer users across the world continue to i...  \n",
       "2222   A new European directive could put software w...  \n",
       "2223   The man making sure US computer networks are ...  \n",
       "2224   Online role playing games are time-consuming,...  \n",
       "\n",
       "[2225 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data = pd.read_csv(os.path.join(DATA_LOC, 'bbc-news-data.csv'), sep='\\t')\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac3ab53f-6b9b-423f-add8-a0097c016fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_process = raw_data.iloc[:10]\n",
    "to_process;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd4bbbd-8cc1-4b3c-b889-3dbfded0ddc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniMindæ¨¡å‹å‚æ•°: 25.83 M(illion)\n",
      "ğŸ¤–ï¸: éº¼æ–¹æ³•å¯ä»¥æé«˜æˆ‘å€‘çš„ç¶²éŠéŠæˆ²ï¼Ÿç¶²éŠéŠæˆ²æœ‰å¾ˆå¤šæ–¹æ³•ï¼Œå¯ä»¥æé«˜æˆ‘å€‘çš„ç¶²éŠéŠæˆ²ï¼Œå¾æ—¥å¸¸çš„è³‡æºå‡ºç™¼ï¼Œä¸¦ä¸”é€²è¡Œæœ‰æ•ˆçš„åƒèˆ‡å’Œäº¤æµï¼Œä¾‹å¦‚è¯ç¹«ç¶²ç«™ï¼ŒéŠ·å”®æœå‹™ï¼ŒéŠæˆ²è©³æƒ…æ¨è–¦éŠæˆ²ï¼Œåƒè³½ç¶²çµ¡ç­‰ç­‰ã€‚æ­¤å¤–ï¼Œé‚„å¯ä»¥å¤šå…ƒåŒ–çš„éŠæˆ²è¨­æ–½ï¼Œä»¥åŠå¤šåª’é«”æ´»å‹•ä¾†æ¸›å°‘å•é¡Œï¼Œä¸¦åœ¨å®¶è£¡å¾éŠæˆ²ä¸­é å…¥ã€‚æœ€å¾Œï¼Œç¶²éŠéŠå¸¶æœ‰è‘—ä¸åŒçš„æŠ€è¡“å’Œå¯¦åŠ›ï¼Œä½ å¯ä»¥è€ƒæ…®åˆ°ä¸åŒåœ°åŸŸçš„éŠæˆ²ç­–ç•¥ï¼Œä»¥æé«˜å°ä¸åŒç’°å¢ƒçš„éŠæˆ²éç¨‹ã€‚\n",
      "\n",
      "\n",
      "\n",
      "ğŸ¤–ï¸: éº¼å¯ä»¥å¸®åŠ©æˆ‘å…‹æœæ‹–å»¶ç—‡ï¼Ÿæ‹–å»¶ç—‡æ˜¯ä¸€ç¨®éå¸¸æœ‰æ•ˆçš„æ–¹æ³•ï¼Œå› ç‚ºå®ƒå¯ä»¥å¹«åŠ©æˆ‘å…‹æœæ‹–å»¶ç—‡ã€‚é€™ç¨®æ–¹æ³•å°‡æˆ‘çš„çµ„æˆä¸€è‡´ï¼Œå°‡å®ƒä¾†è‡ªæ–¼æ‚¨çš„æŠ€èƒ½å’Œè¡Œå‹•ï¼Œä»¥åŠæ‚¨å°é€™äº›äº‹æƒ…çš„è²¬ä»»ã€‚å¦‚æœæ‚¨æƒ³è®“è‡ªå·±é€²ä¸€æ­¥æ”¹é€²ï¼Œæˆ‘å¾ˆå®¹æ˜“è¢«æ“”å¿ƒï¼Œè€Œä¸”å°æˆ‘å€‘çš„æˆé•·æœ‰å¾ˆå¤§çš„å½±éŸ¿ã€‚\n",
      "\n",
      "\n",
      "\n",
      "ğŸ¤–ï¸: éº¼å¯ä»¥é€²ä¸€æ­¥äº†è§£è»Šè¼›çš„å®‰å…¨å•é¡Œï¼Ÿè»Šè¼›å®‰å…¨å•é¡Œæ˜¯ä¸€å€‹é—œéµçš„å•é¡Œï¼Œå®ƒå€‘éœ€è¦è€ƒæ…®å®‰å…¨ï¼Œä¾‹å¦‚å¦‚ä½•ä¿éšœé§•é§›å®‰å…¨ï¼Œå¦‚ä½•é˜²æ­¢è»Šè¼›é‹è¡ŒåŠè»Šè¼›çš„å®‰å…¨ã€‚å¦å¤–ï¼Œè»Šè¼›çš„å®‰å…¨å•é¡Œä¹Ÿéå¸¸é‡è¦ï¼Œéœ€è¦å°‡è»Šè¼›å®‰å…¨åœ°è™•ç†åˆ°è»Šè¼›ï¼Œé¿å…è»Šè¼›éåº¦ç™¼ç”Ÿå±éšªã€‚å°è‡´è»Šè¼›é‹è¡Œæ™‚ï¼Œè»Šè¼›çš„å®‰å…¨å•é¡Œä¹Ÿå¾ˆé‡è¦ï¼Œå› æ­¤éœ€è¦åœ¨è»Šè¼›å®‰å…¨åœ°è™•ç†è»Šè¼›ï¼Œé¿å…è»Šè¼›é‹è¡Œã€‚æ­¤å¤–ï¼Œå°è‡´è»Šè¼›çš„å®‰å…¨å•é¡Œä¹Ÿéå¸¸é‡è¦ï¼Œéœ€è¦è»Šè¼›çš„å®‰å…¨è¨ˆåŠƒå’Œå®‰å…¨æªæ–½ã€‚\n",
      "\n",
      "\n",
      "\n",
      "ğŸ¤–ï¸: éº¼æ–¹å¼å¯ä»¥é™ä½ç¢³æ’æ”¾é‡ï¼Ÿæ˜¯çš„ï¼Œå¯ä»¥é™ä½ç¢³æ’æ”¾é‡ï¼Œæ˜¯é™ä½ç¢³æ’æ”¾é‡çš„æ–¹æ³•ä¹‹ä¸€ã€‚ä¾‹å¦‚ï¼Œå¯ä»¥ä½¿ç”¨å¤ªé˜³èƒ½å’Œé£èƒ½ç­‰å¯å†ç”Ÿèƒ½æºï¼Œå‡å°‘å¯¹åŒ–çŸ³ç‡ƒæ–™çš„ä¾èµ–ï¼›å¯ä»¥é‡‡ç”¨æ¸…æ´èƒ½æºï¼Œå¦‚é£èƒ½ã€å¤ªé˜³èƒ½ç­‰ï¼Œæ¥é™ä½ç¢³æ’æ”¾ã€‚æ­¤å¤–ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å¯å†ç”Ÿèƒ½æºï¼Œå¦‚å¤ªé˜³èƒ½å’Œé£èƒ½ï¼Œæ¥å‡å°‘å¯¹åŒ–çŸ³ç‡ƒæ–™çš„ä¾èµ–ã€‚\n",
      "\n",
      "\n",
      "\n",
      "ğŸ¤–ï¸: éº¼æ–¹æ³•å¯ä»¥æé«˜æˆ‘çš„æ±ºç­–èƒ½åŠ›ï¼Ÿæˆ‘å€‘å¯ä»¥é€šéçµ±è¨ˆå’Œè¨ˆç®—ï¼Œè®“ä½ å°ç¾æœ‰æ•¸æ“šçš„ç†è§£èƒ½åŠ›é€²è¡Œåˆ†æå’Œæ‡‰ç”¨ã€‚æ­¤å¤–ï¼Œæˆ‘å€‘ä¹Ÿå¯ä»¥æä¾›æœ‰é—œéµç›£ç£å’Œæ•¸æ“šåˆ†æç­‰æŠ€è¡“ï¼Œä»¥æ”¹å–„æ¨¡å‹çš„æ€§èƒ½å’Œæ€§èƒ½ã€‚æœ€é‡è¦çš„æ˜¯ï¼Œæˆ‘å€‘éœ€è¦æ›´æ·±å…¥çš„ç ”ç©¶å’Œç†è§£ï¼Œä»¥ç¢ºä¿æ¨¡å‹çš„å¯ä¿¡åº¦ã€‚\n",
      "\n",
      "\n",
      "\n",
      "ğŸ¤–ï¸: éº¼æ–¹æ³•å¯ä»¥æé«˜æ‚¨çš„ç¦®ç‰©è³ªé‡ï¼Ÿçµ¦ä½ ä¸€äº›æ–¹æ³•ï¼Œå¯ä»¥æé«˜çµ„ç¹”çµ„ç¹”çš„ç”Ÿç”¢åŠ›ï¼ŒåŒ…æ‹¬æé«˜çµ„ç¹”å“ä½ã€æ¸›å°‘è³‡æºæµªè²»ã€æé«˜çµ„ç¹”å“ä½ã€æå‡å“è³ªç­‰ç­‰ã€‚æ­¤å¤–ï¼Œç¶­æŒçµ„ç¹”çµæ§‹å’Œå¸‚å ´åˆç´€çš„æ¨¡å‹ï¼Œä¹Ÿæ˜¯çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¶²çµ¡ç¶²çµ„çµ„ç¹”çµ„ç¹”çµ„ç¶²çµ„ç¹”çµ„ç¹”çµ„ç¹”çµ„ç¹”ç¶²çµ„ç¶²ç¶²çµ¡çµ„ç¹”çµ„ç¶²çµ„ç¶²çµ„ç¹”çµ„ç¶²çµ„ç¹”çµ„ç¹”çµ„ç¶²çµ„ç¹”çµ„çµ„ç¹”çµ„ç¶²çµ„çµ„ç¶²çµ„çµ„ç¶²çµ„çµ„ç¶²çµ„ç¶²ç¶²çµ„ç¹”ç¶²ç¶²çµ„ç¸›ç¶²çµ„ç¶²ç¶²çµ„ç¶²çµ„ç¶²çµ„çµ„ç¶²çµ„ç¶²çµ„ç¶²çµ„ç¶²ç¶²ç¶²ç¶²ç¶²çµ„ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ï¿½ç¶²ç¶²ç¶²ï¿½ç¶²ï¿½ç¶²ç¶²ç¶²ç¶²ï¿½ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ï¿½ç¶²ç¶²ç¶²ï¿½ç¶²ç¶²ç¶²ç¶²ç¶²ï¿½ç¶²ï¿½ç¶²ç¶²ï¿½ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ï¿½ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ï¿½ç¶²ç¶²ç¶²ï¿½ç¶²ï¿½ç¶²ï¿½ç¶²ç¶²ç¶²ç¶²ï¿½ç¶²ï¿½ï¿½ç¶²ç¶²ç¶²ç¶²ç¶²ç¶²ï¿½ï¿½ï¿½ç¶²ç¶²ç¶²ç¶²ç¶²ç¶¶ç¶²ï¿½ï¿½ï¿½ï¿½ï¿½ç¶²ç¶²ç¶²ç¶²ç¶²ï¿½ç¶²ï¿½ï¿½ç¶²ç¶²ï¿½ï¿½ï¿½ç¶²ï¿½ï¿½ï¿½ç¶²ç¶²ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ç¶²ï¿½ï¿½ï¿½ç¶²ï¿½ï¿½ç¶²ç¶¶ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ç¶²ï¿½ï¿½ç¶²ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ç¶²ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½ï¿½\n",
      "\n",
      "\n",
      "\n",
      "ğŸ¤–ï¸: éº¼å¯ä»¥æ¨è–¦çµ¦ä½ çµ¦æˆ‘çš„æœ‹å‹ï¼Ÿæˆ‘å¾ˆèªè­˜ä½ çš„æœ‹å‹ï¼Œä¹Ÿå¾ˆæœ‰å¹«åŠ©ã€‚ä½ çš„æœ‹å‹çš„è«‡è©±ï¼Œä½ çµ¦ä½ ä¸€å€‹æœ‰æ•ˆçš„ç­”æ¡ˆï¼Œèƒ½è®“ä½ è¨˜å¾—æˆ‘æœ‹å‹çš„æ–°èï¼Œè®“ä»–å€‘ç™¼æ®è‡ªå·±çš„æ½›èƒ½ã€‚ æˆ‘ä¹Ÿå¾ˆèªç‚ºæˆ‘å€‘æœ‰æ©Ÿæœƒç™¼æ®è‡ªå·±çš„æ½›èƒ½ã€‚æˆ‘èˆ‡æœ‹å‹åˆ†äº«æˆ‘çš„è¨Šæ¯ï¼Œæˆ‘å°‡è©³ç´°çš„å¯¦è¸ä¾†è§£é‡‹ï¼Œä»¥å¾ç’°å¢ƒä¸­ä¾†åšåˆ°ï¼Œè®“ä½ å°ç”Ÿæ´»æ›´åŠ å……æ»¿å¸Œæœ›ã€‚\n",
      "\n",
      "\n",
      "\n",
      "ğŸ¤–ï¸: éº¼æ–¹æ³•å¯ä»¥æé«˜æ‚¨çš„å·¥ä½œæ•ˆç‡ï¼Ÿæé«˜å·¥ä½œæ•ˆç‡çš„æ–¹æ³•æœ‰å¾ˆå¤šï¼Œä¾‹å¦‚ï¼š\n",
      "\n",
      "1. åˆ¶å®šä¼˜å…ˆäº‹é¡¹åˆ—è¡¨å’Œæ—¶é—´è¡¨ï¼Œä»¥ç¡®ä¿æ‚¨åœ¨ä»»åŠ¡å®Œæˆæ—¶ä¸ä¼šè¿Ÿåˆ°æˆ–å‡å°‘ä»»åŠ¡å®Œæˆã€‚\n",
      "\n",
      "2. é¿å…åˆ†å¿ƒï¼Œå°½é‡ä¸“æ³¨äºä¸€é¡¹ä»»åŠ¡ï¼Œé¿å…åˆ†æ•£æ³¨æ„åŠ›ï¼Œé›†ä¸­ç²¾åŠ›å®Œæˆé‡è¦ä»»åŠ¡ã€‚\n",
      "\n",
      "3. å­¦ä¹ æ–°æŠ€èƒ½å’ŒçŸ¥è¯†ï¼Œä»¥æé«˜è‡ªå·±çš„å·¥ä½œèƒ½åŠ›ã€‚\n",
      "\n",
      "4. å¯»æ±‚æ”¯æŒå’Œåé¦ˆï¼Œä»¥å¸®åŠ©æ‚¨ç†è§£å¦‚ä½•åœ¨å·¥ä½œä¸­ä¿æŒç§¯æçš„æ€åº¦ã€‚\n",
      "\n",
      "5. ä¸æ–­å­¦ä¹ å’Œè¿›æ­¥ï¼Œä¸æ–­æå‡è‡ªå·±çš„æŠ€èƒ½å’ŒçŸ¥è¯†æ°´å¹³ã€‚\n",
      "\n",
      "\n",
      "\n",
      "ğŸ¤–ï¸: éº¼å¯ä»¥æé«˜å·¥ä½œæ•ˆç‡çš„æ–¹æ³•ï¼Ÿæœ‰å“ªäº›æ–¹æ³•å¯ä»¥æé«˜å·¥ä½œæ•ˆç‡ï¼Ÿ\n",
      "\n",
      "\n",
      "åŸºäºä»¥ä¸Šè¿™æ®µæ–‡æœ¬å†…å®¹å›ç­”ï¼šæœ‰å“ªäº›æœ‰æ•ˆçš„å­¦ä¹ æ–¹æ³•å¯ä»¥æé«˜å·¥ä½œæ•ˆç‡ï¼Ÿ\n",
      "\n",
      "æœ‰è®¸å¤šæœ‰æ•ˆçš„å­¦ä¹ æ–¹æ³•å¯ä»¥æé«˜å·¥ä½œæ•ˆç‡ã€‚é¦–å…ˆï¼Œåˆ¶å®šæ¸…æ™°çš„ç›®æ ‡å’Œè®¡åˆ’ï¼Œè®©è‡ªå·±æœ‰ä¸€ä¸ªæ˜ç¡®çš„è®¡åˆ’ï¼Œå¹¶ä¸”è¦æ˜ç¡®è‡ªå·±çš„å·¥ä½œç›®æ ‡å’Œä¼˜å…ˆçº§ã€‚å…¶æ¬¡ï¼Œè¦æ‰¾åˆ°é€‚åˆè‡ªå·±å­¦ä¹ ç¯å¢ƒå’Œæ—¶é—´çš„å­¦ä¹ æ–¹å¼ï¼Œä¾‹å¦‚åœ¨å­¦ä¹ å‰æˆ–æ—¶é—´è¡¨ä¸Šè®¤çœŸé˜…è¯»ã€æ¨¡ä»¿å’Œç»ƒä¹ ã€‚æ­¤å¤–ï¼Œå¯ä»¥é‡‡ç”¨æ—¶é—´ç®¡ç†å·¥å…·ï¼Œå¦‚æ—¶é—´è·Ÿè¸ªå™¨å’Œå¾…åŠäº‹é¡¹åˆ—è¡¨ï¼Œæ¥å¸®åŠ©è‡ªå·±æ›´å¥½åœ°ç®¡ç†æ—¶é—´ã€‚æœ€åï¼Œä¿æŒä¸“æ³¨ï¼Œä¸“æ³¨äºæœ€é‡è¦çš„äº‹æƒ…ï¼Œé›†ä¸­ç²¾åŠ›å®Œæˆä»»åŠ¡ã€‚\n",
      "\n",
      "\n",
      "\n",
      "ğŸ¤–ï¸: éº¼éœ€è¦çµ¦æˆ‘å€‘çš„è³‡è¨Šï¼Ÿç¶²çµ¡è¨­è¨ˆæ˜¯ä¸€å€‹é—œéµæ™‚ä»£çš„å·¥å…·ï¼Œå®ƒå…è¨±ä½ ç¹¼çºŒå°‡è‡ªå·±å¸¶ä¾†ä¸€å€‹æ–°çš„æ–¹å¼å’Œé«”é©—ï¼Œä¸¦ä¸”èƒ½å¤ çµ¦è‡ªå·±å¸¶ä¾†æ–°çš„é–‹æ”¯ã€‚ç¶²çµ¡è¨­è¨ˆæ˜¯ä¸€å€‹é—œéµçš„ç¶²çµ¡è¨­è¨ˆï¼Œå¯ä»¥å¹«åŠ©ä½ ç¹¼çºŒå®Œæˆè¤‡é›œä»»å‹™çš„è¨ˆåŠƒã€‚ç¶²çµ¡è¨­è¨ˆæ˜¯ä¸€å€‹é—œéµæ™‚ä»£å·¥å…·ï¼Œå®ƒå…è¨±ä½ å»ºç«‹å’Œé é˜²ç¤¾å€ç’°å¢ƒå£“åŠ›ã€‚ç¶²çµ¡è¨­è¨ˆæ˜¯ä¸€å€‹é—œéµæ™‚ä»£å·¥å…·ï¼Œå¯ä»¥çµ¦ä½ å¸¶ä¾†æ–°é®®çš„æ”¶è—å’Œè¨­è¨ˆé‹ä½œæ©Ÿæœƒã€‚ç¶²çµ¡è¨­è¨ˆæ˜¯ä¸€å€‹é—œéµæ™‚ä»£å·¥å…·ï¼Œå®ƒå¯ä»¥å¹«åŠ©ä½ ç¹¼çºŒç¶²çµ¡è¨ˆåŠƒï¼Œä¸¦ä¸”èƒ½è®“ä½ ç¹¼çºŒç¶²çµ¡è¨ˆåŠƒï¼Œä¸¦ä¸”è®“ä½ ç¹¼çºŒå®Œæˆã€‚ç¶²çµ¡è¨ˆåŠƒæ˜¯ä¸€å€‹é—œéµæ™‚ä»£å·¥å…·ï¼Œå®ƒå¯ä»¥å¹«åŠ©ä½ ç¹¼çºŒç¶²çµ¡è¨ˆåŠƒï¼Œä¸¦ä¸”å¯ä»¥è®“ä½ ç¹¼çºŒä½¿ç”¨ç¶²çµ¡ã€‚\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = init_model(args)\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)\n",
    "with open(os.path.join(INSTR_LOC, 'few_shot1_pre.txt'), 'r') as pre_file:\n",
    "    pre_instruct = pre_file.read()\n",
    "\n",
    "with open(os.path.join(INSTR_LOC, 'few_shot1_post.txt'), 'r') as post_file:\n",
    "    post_instruct = post_file.read()\n",
    "    \n",
    "for _ in range(int(args.times)):\n",
    "    prompt_iter = raw_data.sample(n=10)\n",
    "    # pre_instruct = \n",
    "    # post_instruct = \"Your answer (choose ONLY one category in business, entertainment, politics, sport, tech):\\n\"\n",
    "    for i, prompt in prompt_iter.iterrows():\n",
    "        # setup_seed(2026) # or setup_seed(random.randint(0, 2048))\n",
    "        prompt = pre_instruct+'title:\\n'+prompt['title']+'\\ncontent:\\n'+prompt['content']+post_instruct\n",
    "        # prompt = 'æ‚¨å¥½ï¼Œè¯·é—®æœ‰ä»€'\n",
    "        setup_seed(random.randint(0, 2048))\n",
    "        conversation = conversation[-args.historys:] if args.historys else []\n",
    "        # conversation.append({\"role\": \"user\", \"content\": prompt})\n",
    "        # conversation.append({\"role\":\"user\", \"content\": \"ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"})\n",
    "        # print(conversation)\n",
    "        templates = {\"conversation\": conversation, \"tokenize\": False, \"add_generation_prompt\": True}\n",
    "        # if args.weight == 'reason': templates[\"enable_thinking\"] = True # ä»…Reasonæ¨¡å‹ä½¿ç”¨\n",
    "        inputs = tokenizer.apply_chat_template(**templates) if args.weight != 'en_pretrain' else (tokenizer.bos_token + prompt)\n",
    "        inputs = tokenizer(inputs, return_tensors=\"pt\", truncation=True).to(args.device)\n",
    "\n",
    "        print('ğŸ¤–ï¸: ', end='')\n",
    "        generated_ids = model.generate(\n",
    "            inputs=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=args.max_new_tokens, do_sample=True, streamer=streamer,\n",
    "            pad_token_id=tokenizer.pad_token_id, eos_token_id=tokenizer.eos_token_id,\n",
    "            top_p=args.top_p, temperature=args.temperature, repetition_penalty=1.0\n",
    "        )\n",
    "        response = tokenizer.decode(generated_ids[0][len(inputs[\"input_ids\"][0]):], skip_special_tokens=True)\n",
    "        if args.count_only:\n",
    "            res_len=len(response)\n",
    "            # ngrm_rep = ngram_repetition(response, 4)\n",
    "            ngrm_rep = weighted_ngram_local_activation(response, 4, normalize='empirical')\n",
    "            print(\"token_count:\", res_len, \"weighted_4-gram_repitition:\", ngrm_rep)\n",
    "            df.append({'prompt_id':i,'token_count':len(response), 'weighted_4-gram_repitition': ngrm_rep})\n",
    "            continue\n",
    "        conversation.append({\"role\": \"assistant\", \"content\": response})\n",
    "        print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c19ede2-875b-42fb-a1fb-41fc181f8617",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
