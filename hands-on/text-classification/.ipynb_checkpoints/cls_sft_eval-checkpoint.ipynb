{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9ed3a3c-a3c1-4def-8b2d-be7c60921eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "import pandas as pd\n",
    "import torch\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer\n",
    "from model.model_minimind import MiniMindConfig, MiniMindForCausalLM\n",
    "from model.model_lora import load_lora, apply_lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "281c3628-6d54-4dc5-b56f-2f23d2cd9f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_LOC = '/root/xlcoder/MiniMind2-Small/dataset'\n",
    "INSTR_LOC = '/root/xlcoder/MiniMind2-Small/hands-on'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3983383-d460-42fa-87a8-ce9a4b42c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(os.path.join(DATA_LOC, 'bbc_test_std.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "556ab761-0a3a-4831-948e-500d897da519",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"business\", \"entertainment\", \"politics\", \"sport\", \"tech\"]\n",
    "LABEL_SET = set(LABELS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da90d47f-0f46-43f1-b377-1b80365f83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_label(text: str):\n",
    "    text = text.lower().strip()\n",
    "\n",
    "    # 直接命中\n",
    "    if text in LABEL_SET:\n",
    "        return text\n",
    "\n",
    "    # 在文本中搜索\n",
    "    for label in LABELS:\n",
    "        if re.search(rf\"\\b{label}\\b\", text):\n",
    "            return label\n",
    "\n",
    "    return None  # 解析失败\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67377fa7-5daf-4947-a1f8-77325e56c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationEvalDataset:\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        use_instruction=True,\n",
    "        use_title=True,\n",
    "        instruction_position=\"head\",\n",
    "    ):\n",
    "        self.samples = df\n",
    "\n",
    "        # with open(os.path.join(INSTR_LOC, 'few_shot1_pre.txt'), 'r') as pre_file:\n",
    "        #     self.instruction = pre_file.read()\n",
    "        self.instruction = 'Classify the following passage into one of the categories: business, entertainment, politics, sport, tech.'\n",
    "        self.use_instruction = use_instruction\n",
    "        self.use_title = use_title\n",
    "        self.instruction_position = instruction_position\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def format_prompt(self, ex):\n",
    "        parts = []\n",
    "\n",
    "        instruction = self.instruction\n",
    "        title = ex.title\n",
    "        content = ex.content\n",
    "\n",
    "        if self.use_instruction and self.instruction_position == \"head\":\n",
    "            parts.append(instruction)\n",
    "            parts.append(\"\")\n",
    "\n",
    "        if self.use_title and title:\n",
    "            parts.append(\"Title:\")\n",
    "            parts.append(title)\n",
    "            parts.append(\"\")\n",
    "\n",
    "        parts.append(\"Text:\")\n",
    "        parts.append(content)\n",
    "        parts.append(\"\")\n",
    "\n",
    "        if self.use_instruction and self.instruction_position == \"middle\":\n",
    "            parts.append(instruction)\n",
    "            parts.append(\"\")\n",
    "\n",
    "        parts.append(\"Label:\")\n",
    "\n",
    "        return \"\\n\".join(parts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ebd3d7c-bb41-4723-b40f-1fc46e3ee39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate_classification(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    eval_dataset,\n",
    "    device,\n",
    "    max_new_tokens=8,\n",
    "):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    confusion = defaultdict(lambda: defaultdict(int))\n",
    "    failed = 0\n",
    "\n",
    "    for ex in eval_dataset.samples.iterrows():\n",
    "        ex = ex[1]\n",
    "        prompt = eval_dataset.format_prompt(ex)\n",
    "        gold = ex.category\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            tokenizer.bos_token + prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True\n",
    "        ).to(device)\n",
    "\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        gen_text = tokenizer.decode(\n",
    "            outputs[0][inputs[\"input_ids\"].size(1):],\n",
    "            skip_special_tokens=True\n",
    "        )\n",
    "\n",
    "        pred = parse_label(gen_text)\n",
    "\n",
    "        if pred is None:\n",
    "            failed += 1\n",
    "            continue\n",
    "\n",
    "        confusion[gold][pred] += 1\n",
    "        correct += int(pred == gold)\n",
    "        total += 1\n",
    "\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"total\": total,\n",
    "        \"failed\": failed,\n",
    "        \"confusion\": confusion,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c10b18b-baa0-4dac-81f2-0120a0ade1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLS_TOKENS = {\n",
    "    \"business\": \"<CLS_B>\",\n",
    "    \"entertainment\": \"<CLS_E>\",\n",
    "    \"politics\": \"<CLS_P>\",\n",
    "    \"sport\": \"<CLS_S>\",\n",
    "    \"tech\": \"<CLS_T>\",\n",
    "}\n",
    "\n",
    "def build_cls_id_map(tokenizer):\n",
    "    cls_id_map = {}\n",
    "    for label, tok in CLS_TOKENS.items():\n",
    "        ids = tokenizer(tok, add_special_tokens=False).input_ids\n",
    "        assert len(ids) == 1, f\"{tok} is not single-token!\"\n",
    "        cls_id_map[label] = ids[0]\n",
    "    return cls_id_map\n",
    "    \n",
    "@torch.no_grad()\n",
    "def evaluate_logits_classification(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    eval_dataset,\n",
    "    device,\n",
    "):\n",
    "    model.eval()\n",
    "    cls_id_map = build_cls_id_map(tokenizer)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    confusion = defaultdict(lambda: defaultdict(int))\n",
    "\n",
    "    for ex in eval_dataset.samples.iterrows():\n",
    "        ex = ex[1]\n",
    "        prompt = eval_dataset.format_prompt(ex)\n",
    "        gold = ex.category          # e.g. \"<CLS_P>\"\n",
    "\n",
    "        inputs = tokenizer(\n",
    "            tokenizer.bos_token + prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True\n",
    "        ).to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"]\n",
    "        )\n",
    "\n",
    "        logits = outputs.logits  # [1, seq_len, vocab]\n",
    "        last_pos = inputs[\"attention_mask\"].sum(dim=1).item() - 1\n",
    "\n",
    "        scores = {}\n",
    "        for label, cls_id in cls_id_map.items():\n",
    "            scores[label] = logits[0, last_pos, cls_id].item()\n",
    "\n",
    "        pred = max(scores, key=scores.get)\n",
    "\n",
    "        gold_label = ''\n",
    "        for k, v in CLS_TOKENS.items():\n",
    "            if gold == v:\n",
    "                gold_label = k\n",
    "                break\n",
    "\n",
    "        confusion[gold_label][pred] += 1\n",
    "        correct += int(pred == gold_label)\n",
    "        total += 1\n",
    "\n",
    "    acc = correct / total\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"total\": total,\n",
    "        \"failed\": total - correct,\n",
    "        \"confusion\": confusion,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5277447-22fb-4d8a-8590-d2387382cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion):\n",
    "    labels = LABELS\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(\"gold\\\\pred\".ljust(15) + \"\".join(l.ljust(15) for l in labels))\n",
    "\n",
    "    for g in labels:\n",
    "        row = g.ljust(15)\n",
    "        for p in labels:\n",
    "            row += str(confusion[g].get(p, 0)).ljust(15)\n",
    "        print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06d3e034-7862-4dc9-a23f-f1695fcdfd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_LABELS = [\n",
    "    \"<CLS_B>\",\n",
    "    \"<CLS_E>\",\n",
    "    \"<CLS_P>\",\n",
    "    \"<CLS_S>\",\n",
    "    \"<CLS_T>\",\n",
    "]\n",
    "\n",
    "def init_model(args):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(args.load_from)\n",
    "    tokenizer.add_special_tokens({\n",
    "        \"additional_special_tokens\": SPECIAL_LABELS\n",
    "    })\n",
    "    if 'model' in args.load_from:\n",
    "        model = MiniMindForCausalLM(MiniMindConfig(\n",
    "            hidden_size=args.hidden_size,\n",
    "            num_hidden_layers=args.num_hidden_layers,\n",
    "            use_moe=bool(args.use_moe),\n",
    "            inference_rope_scaling=args.inference_rope_scaling\n",
    "        ))\n",
    "        moe_suffix = '_moe' if args.use_moe else ''\n",
    "        ckp = f'./{args.save_dir}/{args.weight}_{args.hidden_size}{moe_suffix}.pth'\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "        model.load_state_dict(torch.load(ckp, map_location=args.device), strict=True)\n",
    "        if args.lora_weight != 'None':\n",
    "            apply_lora(model, rank=1024)\n",
    "            load_lora(model, f'./{args.save_dir}/lora/{args.lora_weight}_{args.hidden_size}.pth')\n",
    "    else:\n",
    "        model = AutoModelForCausalLM.from_pretrained(args.load_from, trust_remote_code=True)\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "    print(f'MiniMind模型参数: {sum(p.numel() for p in model.parameters()) / 1e6:.2f} M(illion)')\n",
    "    return model.eval().to(args.device), tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e7cab76-6f43-4506-851d-27b8bd4d4f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "args={\n",
    "    'load_from': '../model',\n",
    "    'save_dir': '../out',\n",
    "    'weight': 'en_text_cls_logits',\n",
    "    'lora_weight': 'None',\n",
    "    'hidden_size': 512,\n",
    "    'num_hidden_layers': 8,\n",
    "    'use_moe': 0,\n",
    "    'inference_rope_scaling': False,\n",
    "    'max_new_tokens':8192,\n",
    "    'temperature':0.85,\n",
    "    'top_p':0.85,\n",
    "    'historys':0,\n",
    "    'device':'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'times': 1,\n",
    "    'count_only': False\n",
    "}\n",
    "args = json.loads(json.dumps(args), object_hook=lambda d: SimpleNamespace(**d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1eddd185-5169-4103-9e00-680ecdda8792",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniMind模型参数: 25.83 M(illion)\n",
      "Accuracy: 0.39414414414414417\n",
      "Total: 444\n",
      "Failed: 269\n",
      "\n",
      "Confusion Matrix:\n",
      "gold\\pred      business       entertainment  politics       sport          tech           \n",
      "business       0              0              0              4              98             \n",
      "entertainment  0              0              0              72             5              \n",
      "politics       0              0              0              2              81             \n",
      "sport          0              0              0              102            0              \n",
      "tech           0              0              0              7              73             \n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = init_model(args)\n",
    "\n",
    "eval_ds = ClassificationEvalDataset(\n",
    "    test_data,\n",
    "    use_instruction=True,\n",
    "    use_title=True,\n",
    "    instruction_position=\"head\",\n",
    ")\n",
    "\n",
    "# res = evaluate_classification(\n",
    "#     model,\n",
    "#     tokenizer,\n",
    "#     eval_ds,\n",
    "#     device=args.device,\n",
    "# )\n",
    "\n",
    "res = evaluate_logits_classification(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    eval_ds,\n",
    "    device=args.device,\n",
    ")\n",
    "\n",
    "print(\"Accuracy:\", res[\"accuracy\"])\n",
    "print(\"Total:\", res[\"total\"])\n",
    "print(\"Failed:\", res[\"failed\"])\n",
    "print_confusion_matrix(res[\"confusion\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad704f22-793e-463f-8a7c-0d184d2b1b2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
